% https://conf.researchr.org/track/icsme-2025/icsme-2025-registered-reports
% Submissions to the ICSME 2025 RR track must not exceed 6 pages (plus 1 additional page of references). The page limit is strict. All submissions must be in PDF and must be submitted online by the deadline via the ICSME 2025 EasyChair link.


% 20th May last date.
\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts


%\usepackage{csquotes}
\usepackage{cite}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{algorithm,algorithmic}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{multirow}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{hyperref}
\newcommand{\mytitle}{Assessing Reliability of Statistical Maximum Coverage Estimators in Fuzzing}
\hypersetup{pdftitle={\mytitle},
colorlinks=true,linkcolor=blue,citecolor=blue,filecolor=blue,urlcolor=blue
}

\usepackage{subfig,paralist}
\usepackage{pifont}
\usepackage{enumitem}
\usepackage{url}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow,array}
\usepackage{threeparttable}
%\usepackage{balance}
%\usepackage[group-separator={,}]{siunitx}
%\usepackage[capitalise]{cleveref}
\usepackage{bm}


\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\urlstyle{tt}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}{Lemma}
%\renewcommand\qedsymbol{$\blacksquare$}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\usepackage{tcolorbox}% http://ctan.org/pkg/tcolorbox
\definecolor{mycolor}{rgb}{0.122, 0.435, 0.698}% Rule colour
\definecolor{gray1}{gray}{0.3}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    %backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\tiny\ttfamily,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    columns=fixed
}
\lstset{style=mystyle}

\newcommand{\result}[1]{%
\begin{tcolorbox}[colframe=black,boxrule=0.5pt,arc=4pt,
      left=6pt,right=6pt,top=6pt,bottom=6pt,boxsep=0pt,width=\columnwidth]%
      {\emph{#1}}
\end{tcolorbox}%
}

\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0}
\definecolor{darkred}{rgb}{0.82, 0.1, 0.26}
\newcommand{\cmark}{\textcolor{darkgreen}{\ding{51}}}%
\newcommand{\xmark}{\textcolor{darkred}{\ding{55}}\ }%

\newcommand{\todo}[1]{\noindent\textcolor{red}{TODO:\xspace #1}}
\newcommand{\chk}[1]{\noindent\textcolor{red}{#1\xspace}}

% Section labels
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
\def\subsubsectionautorefname{Section}%%

%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.

\begin{document}

\title{\mytitle}

\author{
\IEEEauthorblockN{Danushka Liyanage}
\IEEEauthorblockA{\textit{School of Computer Science} \\
\textit{University of Sydney}\\
Sydney, Australia \\
danushka.liyanage@sydney.edu.au}
\and 
\IEEEauthorblockN{Rahul Gopinath}
\IEEEauthorblockA{\textit{School of Computer Science} \\
\textit{University of Sydney}\\
Sydney, Australia \\
rahul.gopinath@sydney.edu.au}
}

\maketitle

\thispagestyle{plain}
\pagestyle{plain} 


\begin{abstract}
Fuzzers are often guided by coverage, making the estimation of maximum
possible coverage a key concern in fuzzing.
However, achieving 100\% coverage is impossible for most real-world
software systems, regardless of the time spent fuzzing.
While static analysis of reachability can provide an upper bound,
it is often highly inaccurate.
Recently, statistical estimation based on species richness estimators
in biostatistics have been proposed as a potential solution.
However, a lack of reliable benchmarks with labeled ground truth has
limited a thorough evaluation of the accuracy of this approach.

To address this challenge, we propose an evaluation framework
that generates complex programs with real-world control flow synthetically
where 100\% reachability is assured, providing the
ground-truth for evaluation.
Secondly, we propose a novel check for the reliability of estimators---by
varying the size of sampling units which, under theory should not impact
the estimation.

Using these benchmarks, we propose to empirically evaluate various
species richness estimators under different sampling units.
We aim to identify which estimators demonstrate the highest accuracy against
known ground truth and consistency across sampling units.
Our work will identify the most reliable approaches to estimating maximum
possible coverage in real-world fuzzing campaigns.
\end{abstract}


\section{Introduction}
Fuzzing is an automated testing technique that leverages guidance provided
by coverage. The budget allocated to fuzzing, and hence, the stopping criteria
of fuzzing is strongly determined by the maximum possible coverage that can
be obtained~\cite{fell2017review}.

However, achieving 100\% coverage in software testing is an impossible goal for
complex real-world programs~\cite{horgan1994achieving}.
This is due to the increase in input domain and the corresponding
increase in execution spaces, which makes exhaustive testing
impossible~\cite{knight1996exhaustive}.

Yet, quantifying the maximum possible coverage (also called \emph{maximum reachability})
remains a challenge, which raises a fundamental question:
\emph{How close is a fuzzing campaign to achieving its maximum reachable coverage?}

Recent researches have proposed \emph{species richness estimators} from
biostatistics~\cite{chao2016species} as a principled approach to estimate
the reachable coverage of a fuzzing campaign~\cite{reachability_2023,stads}.
These estimators treat fuzzing as a statistical sampling process in which
each test input belongs to one or more program execution behaviors,
for example, reaching a program element, which can then be leveraged to
estimate the total possible number of such behaviours such as the total
possible reachable elements in a program~\cite{stads,reachability_2023}.
% (e.g., a branch, path, function, or bug).

% Under this analogy, statistical estimators such as Chao2 \cite{chao2017thirty} have been explored to approximate total reachable coverage from partially observed data.

However, evaluating the accuracy and reliability
%(in other words bias and variability)
of these estimators is difficult. The main issue is that, to evaluate such
estimators, we need a benchmark of several large complex programs where
maximum reachability is known. Unfortunately, establishing the maximum
reachability is impossible except for trivial programs. Hence,
rearchers~\cite{reachability_2023} have resorted to using small
programs, fuzzed to saturation as an alternative.
This approach is not ideal as performance of an estimator in small
programs may not representative of the performance of an estimator in complex
real-world programs.

% A recent seminal work by Liyanage et al.~\cite{reachability_2023} proposed two strategies to approximate $S$: (1) using \emph{small-scale} programs that can reach coverage saturation within a reasonable time window, and (2) applying \emph{bootstrapping} (i.e., resampling) techniques based on the empirical species distribution observed in previously collected campaign data. However, both approaches have notable limitations. Small programs often fail to reflect the behavioral complexity and diversity of real-world software, leading to overly optimistic estimator performance. Meanwhile, bootstrapping may poorly approximate the missing mass \cite{residual2021} and can omit behaviors that only emerge late in the campaign.

% \textcolor{red}{ground truth to reliability bridge}

Due to the difficulty of obtaining concrete ground truth for $S$, we investigate alternative, non-ground-truth-based methods for evaluating estimator performance. One important yet often overlooked factor in this context is the definition of the \emph{sampling unit}—that is, how fuzzing inputs are grouped when computing incidence statistics. While prior studies commonly adopt fixed temporal intervals (e.g., 15-minute bins), this arbitrary choice directly impacts the counts of singletons and doubletons, which are critical to estimators such as Chao2. Consequently, it remains unclear whether such estimators produce stable and consistent results under varying sampling granularities. To be considered reliable, an estimator should yield consistent point estimates of maximum reachability across different sampling unit definitions, provided the total campaign length is held constant.

In this paper, we systematically investigate the reliability of incidence-based statistical estimators for fuzzing effectiveness. Drawing on principles from ecology and mutation testing, we introduce a new framework to assess estimator behavior across sampling granularities and examine whether such estimators offer consistent, precise, and upper-bounding estimates of maximum reachability. 

In this paper, we make the following contributions.

\begin{itemize}
    \item \textbf{Critical Analysis of Ground-Truth Methods:} We highlight limitations in current approaches to establishing reachability ground truth, including saturation of small programs and bootstrapped distributions.
    
    \item \textbf{Reliability Framework for Estimators:} We propose a novel framework to assess the reliability of species richness estimators based on their ability to produce consistent point estimates across varying sampling unit sizes at equal campaign durations.
    
    \item \textbf{Empirical Evaluation on Real-World Programs:} We evaluate this framework on 32 real-world programs and demonstrate that certain estimators yield overlapping confidence intervals and reduced variance across different granularities—indicating estimator reliability.
    
    \item \textbf{Assessment of Stopping Criteria:} We re-examine previously proposed stopping criteria and evaluate their effectiveness in identifying when a statistical estimate may serve as a reliable upper bound on maximum reachability.

    \item\textcolor{red}{In this paper we propose a solution to the question of how to interpret the estimate from Chao on time based samples.}
\end{itemize}

The remainder of this paper is organized as follows. Section~\ref{sec:model} introduces the probabilistic model underlying fuzzing and the assumptions made in statistical reachability estimation. Section~\ref{sec:reachability} discusses current approaches to reachability estimation in fuzzing, including existing methods, their associated challenges, proposed solutions, and known drawbacks. Section~\ref{sec:method} presents our methodology for assessing the reliability of statistical estimators of maximum reachability. Section~\ref{sec:setup} details the experimental setup used to evaluate our approach. Finally, Section~\ref{sec:conclusion} concludes the paper and outlines directions for future research.
\input{model.tex}
\input{estimation.tex}
\input{methodology.tex}
\input{setup.tex}
\input{related.tex}


\section{Conclusion}
\label{sec:conclusion}
In this report, we propose to assess the reliability of species estimators when
they are used for estimating reachable coverage. We propose to do that both by
providing a synthetic benchmark with labelled ground truth, and also by
using a separate means of checking the reliability of estimators by variying
the sampling units used.

%\section{Authors and Affiliations}


\bibliographystyle{IEEEtran}
\bibliography{references.bib}


%\section{Acknowledgments}

%% If your work has an appendix, this is the place to put it.
%\appendix

\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
